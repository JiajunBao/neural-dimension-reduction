{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jiajunb/neural-dimension-reduction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7eff60044830>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn import functional as F\n",
    "from src.models.siamese_modeling import SiameseDataSet, SiameseNetwork\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.models.DenseNetwork import loss\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5890fc2f73fb4952b7c6b6bd6b58b5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='create triplets', max=176.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09984d75ce544a57bbd00c3af8a9b7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='create triplets', max=2.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SiameseDataSet.from_df('/home/jiajunb/neural-dimension-reduction/data/train.csv')\n",
    "val_dataset = SiameseDataSet.from_df('/home/jiajunb/neural-dimension-reduction/data/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=1000, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 1e-5\n",
    "learning_rate = 1e-5\n",
    "num_epoches = 40\n",
    "\n",
    "writer = SummaryWriter('runs/siamese_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = SiameseNetwork()\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(\n",
    "        nd in n for nd in no_decay) and p.requires_grad], 'weight_decay': weight_decay},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(\n",
    "        nd in n for nd in no_decay) and p.requires_grad], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.AdamW(params=optimizer_grouped_parameters, lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_loader, model, optimizer, verbose):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    loss_sum = 0.\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        x1, x2, labels = batch\n",
    "        x1, x2, labels = x1.to(device), x2.to(device), labels.to(device)\n",
    "        dist, loss = model(x1, x2, labels)\n",
    "        model.zero_grad()  # reset gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "        if verbose and i % 20 == 0:\n",
    "            print(f'training loss: {loss_sum / (i + 1):.4f}')\n",
    "    return loss_sum / len(train_loader)\n",
    "\n",
    "def val_one_epoch(val_loader, model):\n",
    "    model.eval()\n",
    "    val_contrastive_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            x1, x2, labels = batch\n",
    "            x1, x2, labels = x1.to(device), x2.to(device), labels.to(device)\n",
    "            dist, loss = model(x1, x2, labels)\n",
    "            val_contrastive_loss += loss.item()\n",
    "    return val_contrastive_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_eval(train_loader, val_loader, model, optimizer, num_epoches, verbose):\n",
    "    global writer\n",
    "    best_model = None\n",
    "    best_avg_val_contrastive_loss = float('inf')\n",
    "    for epoch_idx in range(1, num_epoches + 1):\n",
    "        avg_loss = train_one_epoch(train_loader, model, optimizer, False)\n",
    "        avg_val_contrastive_loss = val_one_epoch(val_loader, model)\n",
    "        if avg_val_contrastive_loss <  best_avg_val_contrastive_loss:\n",
    "            best_avg_val_contrastive_loss = avg_val_contrastive_loss\n",
    "            best_model = copy.deepcopy(model.cpu())\n",
    "        writer.add_scalar('train/avg_mixed_loss', avg_loss, epoch_idx)\n",
    "        writer.add_scalar('val/avg_val_contrastive_loss', avg_val_contrastive_loss, epoch_idx)\n",
    "        if verbose and epoch_idx % 4 == 0:\n",
    "            print(f'epoch [{epoch_idx}]/[{num_epoches}] training loss: {avg_loss:.4f} '\n",
    "                  f'avg_val_contrastive_loss: {avg_val_contrastive_loss:.4f} ')\n",
    "    return best_avg_val_contrastive_loss, best_model, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=1000, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [4]/[40] training loss: 0.0893 avg_val_contrastive_loss: 0.1769 \n",
      "epoch [8]/[40] training loss: 0.0650 avg_val_contrastive_loss: 0.1839 \n",
      "epoch [12]/[40] training loss: 0.0487 avg_val_contrastive_loss: 0.1916 \n",
      "epoch [16]/[40] training loss: 0.0360 avg_val_contrastive_loss: 0.1992 \n",
      "epoch [20]/[40] training loss: 0.0258 avg_val_contrastive_loss: 0.2019 \n",
      "epoch [24]/[40] training loss: 0.0178 avg_val_contrastive_loss: 0.2033 \n",
      "epoch [28]/[40] training loss: 0.0125 avg_val_contrastive_loss: 0.2041 \n",
      "epoch [32]/[40] training loss: 0.0098 avg_val_contrastive_loss: 0.2069 \n",
      "epoch [36]/[40] training loss: 0.0078 avg_val_contrastive_loss: 0.2137 \n",
      "epoch [40]/[40] training loss: 0.0067 avg_val_contrastive_loss: 0.2128 \n"
     ]
    }
   ],
   "source": [
    "best_avg_val_contrastive_loss, best_model, final_model = train_with_eval(train_loader, val_loader, model, optimizer, num_epoches, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     \"best_model\": best_model.state_dict(),\n",
    "#     \"best_avg_val_contrastive_loss\": best_avg_val_contrastive_loss\n",
    "# }, '../saves/siamese.on.full.0.0067')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(data_loader, model):\n",
    "    model.eval()\n",
    "    embedding = list()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            x = batch[0].to(device)\n",
    "            out = model.encode_batch(x)\n",
    "            embedding.append(out.cpu())\n",
    "    return torch.cat(embedding, dim=0)\n",
    "best_model = best_model.to(device)\n",
    "val_nn_loader = DataLoader(TensorDataset(val_dataset.data.clone()), batch_size=1000, pin_memory=True)\n",
    "val_x_embedded = extract_embeddings(val_nn_loader, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrieveSystem(object):\n",
    "    def __init__(self, distance_measure):\n",
    "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        distance_measure = distance_measure.to(self.device)\n",
    "        self.distance_measure = distance_measure\n",
    "\n",
    "    def retrieve_query(self, query, ignore_idx, x_embedded, x_idx, topk=20):\n",
    "        query_device = query.view(1, -1).to(self.device)\n",
    "        cls_distances = list()\n",
    "        with torch.no_grad():\n",
    "            for i, x in zip(x_idx, x_embedded):\n",
    "                if ignore_idx is not None and i == ignore_idx:\n",
    "                    continue\n",
    "                x_device = x.view(1, -1).to(self.device)\n",
    "                logits = self.distance_measure.decode_batch(query_device, x_device)\n",
    "                cls_distances.append(logits.item())\n",
    "                \n",
    "        cls_distances = torch.tensor(cls_distances)\n",
    "        _, cls_nn_idx = cls_distances.sort(descending=False)\n",
    "        return cls_nn_idx[:topk]\n",
    "\n",
    "    def retrieve_corpus(self, corpus, block_list, database):\n",
    "        cls_pred_nn_top = list()\n",
    "        x_idx = range(database.shape[0])\n",
    "        for ignore_idx, query in tqdm(zip(block_list, corpus), total=len(block_list), desc='retrieve each query'):\n",
    "            cls_distances = self.retrieve_query(query, ignore_idx, database, x_idx, 20)\n",
    "            cls_pred_nn_top.append(cls_distances.view(1, -1))\n",
    "        cls_pred_nn_top = torch.cat(cls_pred_nn_top, dim=0)\n",
    "        return cls_pred_nn_top\n",
    "\n",
    "    def recall(self, pred, gold, at_n=None):\n",
    "        results = dict()\n",
    "        if at_n is None:\n",
    "            at_n = [1, 5, 10, 20]\n",
    "        for n in at_n:\n",
    "            recall = float((pred[:, :n] == gold.view(-1, 1)).sum().item()) / len(gold)\n",
    "            results[f'recall@{n}'] = recall\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ab2cff669e42b0b727f6c95ea07a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='retrieve each query', max=1000.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "retriever = RetrieveSystem(best_model)\n",
    "block_list = torch.arange(val_x_embedded.shape[0])\n",
    "cls_pred_nn_top = retriever.retrieve_corpus(val_x_embedded, block_list, val_x_embedded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, gold, _ = loss.nearest_neighbors(val_dataset.data.clone(), top_k=1, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 20])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pred_nn_top.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float((cls_pred_nn_top[:, :5] == gold.view(-1, 1)).sum()) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
