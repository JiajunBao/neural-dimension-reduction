{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/jiajunb/neural-dimension-reduction/data/processed/sample/train.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95.195544</td>\n",
       "      <td>12.221859</td>\n",
       "      <td>47.141783</td>\n",
       "      <td>75.731650</td>\n",
       "      <td>68.580790</td>\n",
       "      <td>83.656304</td>\n",
       "      <td>16.142661</td>\n",
       "      <td>10.761436</td>\n",
       "      <td>24.584586</td>\n",
       "      <td>64.646126</td>\n",
       "      <td>...</td>\n",
       "      <td>55.934230</td>\n",
       "      <td>81.640514</td>\n",
       "      <td>60.744191</td>\n",
       "      <td>97.305761</td>\n",
       "      <td>7.392480</td>\n",
       "      <td>13.650104</td>\n",
       "      <td>22.542291</td>\n",
       "      <td>29.720707</td>\n",
       "      <td>37.517233</td>\n",
       "      <td>4.450282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.166320</td>\n",
       "      <td>15.227976</td>\n",
       "      <td>44.293374</td>\n",
       "      <td>78.179281</td>\n",
       "      <td>64.172340</td>\n",
       "      <td>85.974963</td>\n",
       "      <td>12.933176</td>\n",
       "      <td>12.588127</td>\n",
       "      <td>27.508371</td>\n",
       "      <td>65.913688</td>\n",
       "      <td>...</td>\n",
       "      <td>55.372351</td>\n",
       "      <td>82.652559</td>\n",
       "      <td>59.682662</td>\n",
       "      <td>93.990164</td>\n",
       "      <td>7.141942</td>\n",
       "      <td>15.400499</td>\n",
       "      <td>17.470659</td>\n",
       "      <td>26.153575</td>\n",
       "      <td>38.005573</td>\n",
       "      <td>3.043574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.596314</td>\n",
       "      <td>51.122708</td>\n",
       "      <td>22.307158</td>\n",
       "      <td>47.822319</td>\n",
       "      <td>91.865922</td>\n",
       "      <td>45.266854</td>\n",
       "      <td>93.859339</td>\n",
       "      <td>75.470586</td>\n",
       "      <td>40.011441</td>\n",
       "      <td>48.181460</td>\n",
       "      <td>...</td>\n",
       "      <td>62.268754</td>\n",
       "      <td>65.520484</td>\n",
       "      <td>63.083167</td>\n",
       "      <td>57.314553</td>\n",
       "      <td>36.625940</td>\n",
       "      <td>19.176103</td>\n",
       "      <td>58.446734</td>\n",
       "      <td>6.461213</td>\n",
       "      <td>21.434521</td>\n",
       "      <td>28.600447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.726750</td>\n",
       "      <td>44.311964</td>\n",
       "      <td>38.018275</td>\n",
       "      <td>7.328273</td>\n",
       "      <td>88.471305</td>\n",
       "      <td>39.343504</td>\n",
       "      <td>9.586104</td>\n",
       "      <td>26.378220</td>\n",
       "      <td>13.760890</td>\n",
       "      <td>84.802381</td>\n",
       "      <td>...</td>\n",
       "      <td>39.916273</td>\n",
       "      <td>33.357095</td>\n",
       "      <td>26.539032</td>\n",
       "      <td>40.089722</td>\n",
       "      <td>66.134136</td>\n",
       "      <td>51.373676</td>\n",
       "      <td>18.746099</td>\n",
       "      <td>48.416866</td>\n",
       "      <td>64.521661</td>\n",
       "      <td>31.214616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.538269</td>\n",
       "      <td>96.397863</td>\n",
       "      <td>27.843163</td>\n",
       "      <td>89.924001</td>\n",
       "      <td>78.159261</td>\n",
       "      <td>78.381714</td>\n",
       "      <td>14.137873</td>\n",
       "      <td>67.815051</td>\n",
       "      <td>89.252998</td>\n",
       "      <td>53.251439</td>\n",
       "      <td>...</td>\n",
       "      <td>86.379488</td>\n",
       "      <td>93.653028</td>\n",
       "      <td>87.877870</td>\n",
       "      <td>-0.110282</td>\n",
       "      <td>85.945464</td>\n",
       "      <td>30.948948</td>\n",
       "      <td>22.571470</td>\n",
       "      <td>83.076293</td>\n",
       "      <td>7.505366</td>\n",
       "      <td>33.383922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>95.988460</td>\n",
       "      <td>96.597039</td>\n",
       "      <td>6.417373</td>\n",
       "      <td>11.864794</td>\n",
       "      <td>29.096424</td>\n",
       "      <td>51.156862</td>\n",
       "      <td>70.729162</td>\n",
       "      <td>0.053391</td>\n",
       "      <td>47.769190</td>\n",
       "      <td>8.089639</td>\n",
       "      <td>...</td>\n",
       "      <td>33.746159</td>\n",
       "      <td>84.972306</td>\n",
       "      <td>78.887586</td>\n",
       "      <td>22.991115</td>\n",
       "      <td>86.330459</td>\n",
       "      <td>67.422775</td>\n",
       "      <td>12.524036</td>\n",
       "      <td>0.086390</td>\n",
       "      <td>30.022850</td>\n",
       "      <td>45.891306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>98.950657</td>\n",
       "      <td>96.770066</td>\n",
       "      <td>4.619809</td>\n",
       "      <td>11.878924</td>\n",
       "      <td>30.487113</td>\n",
       "      <td>49.628742</td>\n",
       "      <td>69.548092</td>\n",
       "      <td>0.311771</td>\n",
       "      <td>45.514677</td>\n",
       "      <td>8.905408</td>\n",
       "      <td>...</td>\n",
       "      <td>32.391831</td>\n",
       "      <td>82.134732</td>\n",
       "      <td>79.151044</td>\n",
       "      <td>23.002295</td>\n",
       "      <td>84.818998</td>\n",
       "      <td>70.569570</td>\n",
       "      <td>12.428116</td>\n",
       "      <td>-0.077022</td>\n",
       "      <td>28.128708</td>\n",
       "      <td>45.544241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>44.181214</td>\n",
       "      <td>7.364665</td>\n",
       "      <td>47.728003</td>\n",
       "      <td>46.507556</td>\n",
       "      <td>92.448435</td>\n",
       "      <td>84.817303</td>\n",
       "      <td>85.524844</td>\n",
       "      <td>20.197726</td>\n",
       "      <td>56.884943</td>\n",
       "      <td>21.684099</td>\n",
       "      <td>...</td>\n",
       "      <td>43.780489</td>\n",
       "      <td>47.282330</td>\n",
       "      <td>42.974455</td>\n",
       "      <td>54.554699</td>\n",
       "      <td>63.130056</td>\n",
       "      <td>23.894714</td>\n",
       "      <td>12.693856</td>\n",
       "      <td>25.860484</td>\n",
       "      <td>81.959900</td>\n",
       "      <td>19.465354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>87.065177</td>\n",
       "      <td>41.652331</td>\n",
       "      <td>36.694405</td>\n",
       "      <td>6.778014</td>\n",
       "      <td>90.055636</td>\n",
       "      <td>36.665053</td>\n",
       "      <td>9.999484</td>\n",
       "      <td>24.324081</td>\n",
       "      <td>15.838263</td>\n",
       "      <td>84.286281</td>\n",
       "      <td>...</td>\n",
       "      <td>37.389795</td>\n",
       "      <td>33.416162</td>\n",
       "      <td>29.278542</td>\n",
       "      <td>40.517507</td>\n",
       "      <td>63.278387</td>\n",
       "      <td>48.665805</td>\n",
       "      <td>15.918664</td>\n",
       "      <td>49.526287</td>\n",
       "      <td>66.486111</td>\n",
       "      <td>35.752724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>57.217716</td>\n",
       "      <td>84.786703</td>\n",
       "      <td>79.810891</td>\n",
       "      <td>72.846562</td>\n",
       "      <td>38.329703</td>\n",
       "      <td>46.823894</td>\n",
       "      <td>4.912598</td>\n",
       "      <td>53.275286</td>\n",
       "      <td>37.648566</td>\n",
       "      <td>38.550918</td>\n",
       "      <td>...</td>\n",
       "      <td>91.371144</td>\n",
       "      <td>3.355578</td>\n",
       "      <td>46.463727</td>\n",
       "      <td>36.951946</td>\n",
       "      <td>14.769391</td>\n",
       "      <td>45.976139</td>\n",
       "      <td>31.290845</td>\n",
       "      <td>25.800302</td>\n",
       "      <td>22.351810</td>\n",
       "      <td>92.636052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5    \\\n",
       "0     95.195544  12.221859  47.141783  75.731650  68.580790  83.656304   \n",
       "1     99.166320  15.227976  44.293374  78.179281  64.172340  85.974963   \n",
       "2     43.596314  51.122708  22.307158  47.822319  91.865922  45.266854   \n",
       "3     83.726750  44.311964  38.018275   7.328273  88.471305  39.343504   \n",
       "4      7.538269  96.397863  27.843163  89.924001  78.159261  78.381714   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1995  95.988460  96.597039   6.417373  11.864794  29.096424  51.156862   \n",
       "1996  98.950657  96.770066   4.619809  11.878924  30.487113  49.628742   \n",
       "1997  44.181214   7.364665  47.728003  46.507556  92.448435  84.817303   \n",
       "1998  87.065177  41.652331  36.694405   6.778014  90.055636  36.665053   \n",
       "1999  57.217716  84.786703  79.810891  72.846562  38.329703  46.823894   \n",
       "\n",
       "            6          7          8          9    ...        190        191  \\\n",
       "0     16.142661  10.761436  24.584586  64.646126  ...  55.934230  81.640514   \n",
       "1     12.933176  12.588127  27.508371  65.913688  ...  55.372351  82.652559   \n",
       "2     93.859339  75.470586  40.011441  48.181460  ...  62.268754  65.520484   \n",
       "3      9.586104  26.378220  13.760890  84.802381  ...  39.916273  33.357095   \n",
       "4     14.137873  67.815051  89.252998  53.251439  ...  86.379488  93.653028   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1995  70.729162   0.053391  47.769190   8.089639  ...  33.746159  84.972306   \n",
       "1996  69.548092   0.311771  45.514677   8.905408  ...  32.391831  82.134732   \n",
       "1997  85.524844  20.197726  56.884943  21.684099  ...  43.780489  47.282330   \n",
       "1998   9.999484  24.324081  15.838263  84.286281  ...  37.389795  33.416162   \n",
       "1999   4.912598  53.275286  37.648566  38.550918  ...  91.371144   3.355578   \n",
       "\n",
       "            192        193        194        195        196        197  \\\n",
       "0     60.744191  97.305761   7.392480  13.650104  22.542291  29.720707   \n",
       "1     59.682662  93.990164   7.141942  15.400499  17.470659  26.153575   \n",
       "2     63.083167  57.314553  36.625940  19.176103  58.446734   6.461213   \n",
       "3     26.539032  40.089722  66.134136  51.373676  18.746099  48.416866   \n",
       "4     87.877870  -0.110282  85.945464  30.948948  22.571470  83.076293   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1995  78.887586  22.991115  86.330459  67.422775  12.524036   0.086390   \n",
       "1996  79.151044  23.002295  84.818998  70.569570  12.428116  -0.077022   \n",
       "1997  42.974455  54.554699  63.130056  23.894714  12.693856  25.860484   \n",
       "1998  29.278542  40.517507  63.278387  48.665805  15.918664  49.526287   \n",
       "1999  46.463727  36.951946  14.769391  45.976139  31.290845  25.800302   \n",
       "\n",
       "            198        199  \n",
       "0     37.517233   4.450282  \n",
       "1     38.005573   3.043574  \n",
       "2     21.434521  28.600447  \n",
       "3     64.521661  31.214616  \n",
       "4      7.505366  33.383922  \n",
       "...         ...        ...  \n",
       "1995  30.022850  45.891306  \n",
       "1996  28.128708  45.544241  \n",
       "1997  81.959900  19.465354  \n",
       "1998  66.486111  35.752724  \n",
       "1999  22.351810  92.636052  \n",
       "\n",
       "[2000 rows x 200 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def pairwise_distance(x):\n",
    "    \"\"\"\n",
    "    calculate the nearest neighbors of x, return the\n",
    "    :param x: for matrix to calculate nearest neighbor\n",
    "    :return:\n",
    "        dist: pairwise distances\n",
    "    \"\"\"\n",
    "    batch_size = 2000\n",
    "    if x.shape[0] * x.shape[1] < batch_size * 200:  # direct computes the whole matrix\n",
    "        dist = torch.cdist(x1=x, x2=x, p=2)  # (n, n)\n",
    "    else:  # calculate the nearest neighbors in batches\n",
    "        num_iter = x.shape[0] // batch_size + 1\n",
    "        dist = list()\n",
    "        for i in torch.arange(num_iter):\n",
    "            batch_x = x[i * batch_size: (i + 1) * batch_size, :]\n",
    "            dist.append(torch.cdist(x1=batch_x, x2=x, p=2))  # (n, n)\n",
    "        dist = torch.cat(dist, dim=0)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def softmin_probability(xdist_batch, sigma):\n",
    "    n = xdist_batch.shape[0]\n",
    "    idx = torch.arange(n)\n",
    "    d = -xdist_batch.square() / 2 / (sigma ** 2)\n",
    "    d = d - torch.mean(d)\n",
    "    p = d.exp()\n",
    "    \n",
    "    p[idx, idx] = 0\n",
    "    p = p / p.sum(dim=1, keepdim=True)\n",
    "    p[idx, idx] = 0\n",
    "    return p\n",
    "\n",
    "\n",
    "def calculate_perplexity(prob):\n",
    "    n = prob.shape[0]\n",
    "    idx = torch.arange(n)\n",
    "    entropy = torch.log2(prob) * prob\n",
    "    entropy[idx, idx] = 0\n",
    "    hp = -torch.sum(entropy, dim=1)\n",
    "    print('hp', hp)\n",
    "    print(torch.log2(prob) * prob)\n",
    "    return 2 ** hp\n",
    "\n",
    "\n",
    "def get_input_probability(x_dist_batch, ppl):\n",
    "    sigma = 1.\n",
    "    data_ppl = calculate_perplexity(softmin_probability(x_dist_batch, sigma))\n",
    "    while (data_ppl - ppl).norm(p=2) < 1e-3:\n",
    "        sigma *= 2\n",
    "    return sigma\n",
    "\n",
    "\n",
    "def get_output_probability(y, alpha):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist = pairwise_distance(torch.from_numpy(train.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(411710.4468, dtype=torch.float64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dist ** 2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dist ** 2).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5675, dtype=torch.float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(0-(dist ** 2) / 2 / (5e2 ** 2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 5.5308e-03, 1.1015e-81,  ..., 6.3476e-80, 1.2650e-74,\n",
      "         4.6448e-85],\n",
      "        [5.6170e-03, 0.0000e+00, 1.4080e-80,  ..., 1.6410e-79, 4.9491e-74,\n",
      "         2.1821e-83],\n",
      "        [1.0393e-81, 1.3081e-80, 0.0000e+00,  ..., 2.8777e-76, 4.4245e-87,\n",
      "         1.3808e-87],\n",
      "        ...,\n",
      "        [7.5351e-80, 1.9181e-79, 3.6205e-76,  ..., 0.0000e+00, 2.1126e-80,\n",
      "         2.0255e-88],\n",
      "        [9.5166e-75, 3.6661e-74, 3.5279e-87,  ..., 1.3389e-80, 0.0000e+00,\n",
      "         3.4107e-82],\n",
      "        [4.5517e-85, 2.1056e-83, 1.4342e-87,  ..., 1.6721e-88, 4.4427e-82,\n",
      "         0.0000e+00]], dtype=torch.float64)\n",
      "hp tensor([7.5798, 7.5812, 7.7171,  ..., 7.6934, 7.7785, 7.4232],\n",
      "       dtype=torch.float64)\n",
      "tensor([[        nan, -4.1472e-02, -2.9624e-79,  ..., -1.6700e-77,\n",
      "         -3.1053e-72, -1.3012e-82],\n",
      "        [-4.1993e-02,         nan, -3.7349e-78,  ..., -4.2948e-77,\n",
      "         -1.2052e-71, -5.9920e-81],\n",
      "        [-2.7960e-79, -3.4713e-78,         nan,  ..., -7.2213e-74,\n",
      "         -1.2692e-84, -3.9843e-85],\n",
      "        ...,\n",
      "        [-1.9805e-77, -5.0157e-77, -9.0735e-74,  ...,         nan,\n",
      "         -5.5915e-78, -5.9004e-86],\n",
      "        [-2.3401e-72, -8.9435e-72, -1.0132e-84,  ..., -3.5524e-78,\n",
      "                 nan, -9.2302e-80],\n",
      "        [-1.2753e-82, -5.7829e-81, -4.1374e-85,  ..., -4.8755e-86,\n",
      "         -1.2006e-79,         nan]], dtype=torch.float64)\n",
      "tensor([191.3087, 191.5023, 210.4178,  ..., 206.9846, 219.5608, 171.6315],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = softmin_probability(dist, 30)\n",
    "print(x)\n",
    "ppl = calculate_perplexity(x)\n",
    "print(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dist_batch.square() / 2 / (30 ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
